{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5bPIdlDVmJI",
        "outputId": "1c570a43-7a05-4a2f-8495-b99d3d614f8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.4/269.4 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_sKW_hVNNYXg"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import json\n",
        "import moviepy.editor as mp\n",
        "\n",
        "openai.api_key = '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'\n",
        "video_file_name = 'Finance.mp4' #'phone review.mp4'\n",
        "video_end_sec = 60\n",
        "audio_file_name = video_file_name.split('.')[0] + '.mp3'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "983wthz3HPel",
        "outputId": "bbb14a6a-7598-4f06-e386-bf3f934c08ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Writing audio in Finance.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n"
          ]
        }
      ],
      "source": [
        "clip = mp.VideoFileClip(video_file_name)\n",
        "duration = 800 #clip.duration\n",
        "\n",
        "mod_clip = clip.subclip(0,duration)\n",
        "\n",
        "mod_clip.audio.write_audiofile(audio_file_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lO7PDvUiV5eu"
      },
      "outputs": [],
      "source": [
        "audio_file= open(audio_file_name, \"rb\")\n",
        "\n",
        "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "\n",
        "# Convert the JSON object to a JSON-formatted string\n",
        "transcript = json.dumps(transcript)\n",
        "# Save to txt file\n",
        "with open(\"input.txt\", \"w\") as file:\n",
        "    file.write(transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GLx3SMhTYSkj"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "import nltk\n",
        "\n",
        "def generate_sentiment_score(paragraph):\n",
        "    \n",
        "    # Tokenize sentences\n",
        "    review = nltk.sent_tokenize(paragraph)\n",
        "\n",
        "    prompt = f\"Give me the sentiment score(1-10) of the following review, just give me a number': {review}\"\n",
        "    \n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=50,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "        \n",
        "    summary = response.choices[0].text.strip()\n",
        "    return summary\n",
        "\n",
        "def generate_topic(paragraph):\n",
        "    \n",
        "    # Tokenize sentences\n",
        "    review = nltk.sent_tokenize(paragraph)\n",
        "\n",
        "    prompt = f\"Give me the topic of the following review, within 3 words': {review}\"\n",
        "    \n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=50,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "        \n",
        "    summary = response.choices[0].text.strip()\n",
        "    return summary\n",
        "\n",
        "def generate_theme(paragraph):\n",
        "    \n",
        "    # Tokenize sentences\n",
        "    review = nltk.sent_tokenize(paragraph)\n",
        "\n",
        "    prompt = f\"Give me a theme of the following review': {review}\"\n",
        "    \n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=50,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "        \n",
        "    summary = response.choices[0].text.strip()\n",
        "    return summary\n",
        "\n",
        "def generate_summary(paragraph):\n",
        "    \n",
        "    # Tokenize sentences\n",
        "    review = nltk.sent_tokenize(paragraph)\n",
        "\n",
        "    prompt = f\"Give me a short summarize of the following review': {review}\"\n",
        "    \n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=50,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "        \n",
        "    summary = response.choices[0].text.strip()\n",
        "    return summary\n",
        "\n",
        "def generate_report(paragraph):\n",
        "    \n",
        "    # Tokenize sentences\n",
        "    review = nltk.sent_tokenize(paragraph)\n",
        "\n",
        "    prompt = f\"Give me a few points of summary of the following, including the merits and the problems': {review}\"\n",
        "    \n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=2000,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "        \n",
        "    summary = response.choices[0].text.strip()\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS9UOXX_UlCW",
        "outputId": "e54d44bd-2bcf-4479-bb01-0fb0722af5df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tourism Impact\n"
          ]
        }
      ],
      "source": [
        "# audio_file= open(audio_file_name, \"rb\")\n",
        "\n",
        "# transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "\n",
        "# # Convert the JSON object to a JSON-formatted string\n",
        "# transcript = json.dumps(transcript)\n",
        "# # Save to txt file\n",
        "# with open(\"input.txt\", \"w\") as file:\n",
        "#     file.write(transcript)\n",
        "\n",
        "#Uncomment below to run each\n",
        "\n",
        "# generate_sentiment_score(transcript)\n",
        "generate_topic(transcript)\n",
        "# generate_theme(transcript)\n",
        "# generate_summary(transcript)\n",
        "# generate_report(transcript)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "vRVB1HxJ5nk8",
        "outputId": "fb0a8d82-6657-4ab0-ac47-841a47ffe09c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'This review is about the impact of COVID-19 on the tourism industry, particularly in Waipa District. It covers the economic impact of the virus including job losses and business closures, the loss of international visitors, the impact of airline'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_summary(transcript)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MgqJhJtNArE7",
        "outputId": "6a6c11bf-3ca7-4130-a0e8-38a6f5383afd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Theme: The Impact of COVID-19 on the Tourism Industry'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_theme(transcript)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "mNaCNtyLAZmP",
        "outputId": "a07a14e2-8d99-421b-f459-055003763aed"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-010214f15c46>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    folder_path = \"C:\\Users\\awahi01\\Downloads\"\u001b[0m\n\u001b[0m                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pydub import AudioSegment\n",
        "import openai\n",
        "\n",
        "# Set the path to the folder containing the MP3 files\n",
        "folder_path = \"C:\\Users\\awahi01\\Downloads\"\n",
        "\n",
        "# Initialize an empty dataframe to store the audio file information\n",
        "df = pd.DataFrame(columns=[\"filename\", \"audio_data\",\"file_type\"])\n",
        "\n",
        "# Loop through all the MP3 files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    #print(filename)\n",
        "    if filename.endswith(\".mp3\"):\n",
        "        # Load the audio file and get its raw audio data\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        #print(file_path)\n",
        "        audio_file= open(file_path, \"rb\")        \n",
        "        print(\"read_audio_file\")\n",
        "        print(\"path completed\")\n",
        "        # Add the filename and audio data to the dataframe\n",
        "        #convert mp3 into transcript\n",
        "        transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "\n",
        "        # Convert the JSON object to a JSON-formatted string\n",
        "        transcript = json.dumps(transcript)\n",
        "\n",
        "        df = df.append({\"filename\": filename, \"audio_data\": transcript,\"file_type\":\"audio\"}, ignore_index=True)\n",
        "    \n",
        "    elif filename.endswith(\".mp4\"):\n",
        "\n",
        "      # Load the video file and get its raw video data\n",
        "      file_path = os.path.join(folder_path, filename)\n",
        "      audio_file_name = file_path.split('.')[0] + '.mp3'\n",
        "      clip = mp.VideoFileClip(file_path)\n",
        "      duration = clip.duration\n",
        "      mod_clip = clip.subclip(0,duration)\n",
        "      mod_clip.audio.write_audiofile(audio_file_name)\n",
        "      audio_file= open(audio_file_name, \"rb\")\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "      transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "      transcript = json.dumps(transcript)\n",
        "      df = df.append({\"filename\": filename, \"audio_data\": transcript,\"file_type\":\"video\"}, ignore_index=True)\n",
        "\n",
        "df\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
